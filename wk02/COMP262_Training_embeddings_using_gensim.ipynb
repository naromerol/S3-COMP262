{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2WGPwjhbbwPT"
   },
   "source": [
    "## Training Embeddings Using Gensim\n",
    "Word embeddings are an approach to representing text in NLP. In this notebook we will demonstrate how to train embeddings using Genism. [Gensim](https://radimrehurek.com/gensim/index.html) is an open source Python library for natural language processing, with a focus on topic modeling (explained in chapter 7)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-05T21:26:40.863650Z",
     "start_time": "2021-04-05T21:26:40.339123Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "TBw9OCYcYQ_n"
   },
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-05T21:26:40.894143Z",
     "start_time": "2021-04-05T21:26:40.865114Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "5qWptd54ZcfV"
   },
   "outputs": [],
   "source": [
    "# define training data\n",
    "#Genism word2vec requires that a format of ‘list of lists’ be provided for training where every document contained in a list.\n",
    "#Every list contains lists of tokens of that document.\n",
    "corpus = [['dog','bites','man'], [\"man\", \"bites\" ,\"dog\"],[\"dog\",\"eats\",\"meat\"],[\"man\", \"eats\",\"food\"]]\n",
    "\n",
    "#Training the model\n",
    "model_cbow = Word2Vec(corpus, min_count=1,sg=0) #using CBOW Architecture for trainnig\n",
    "model_skipgram = Word2Vec(corpus, min_count=1,sg=1)#using skipGram Architecture for training "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0QjSxefPl4mh"
   },
   "source": [
    "## Continuous Bag of Words (CBOW) \n",
    "In CBOW, the primary task is to build a language model that correctly predicts the center word given the context words in which the center word appears."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-05T21:26:56.724662Z",
     "start_time": "2021-04-05T21:26:56.712651Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 486
    },
    "colab_type": "code",
    "id": "nyZY8ME4lUjd",
    "outputId": "bd00e825-c11a-4b36-dbf5-80f32c659956"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word2Vec(vocab=6, size=100, alpha=0.025)\n",
      "['dog', 'bites', 'man', 'eats', 'meat', 'food']\n",
      "[-3.9270632e-03  2.9621110e-03 -3.7891304e-03  2.8326416e-03\n",
      "  2.3133212e-03  3.7316212e-03 -3.8585411e-03  2.6184537e-03\n",
      "  3.0876028e-03  2.1837868e-03 -2.7802046e-03  3.0769829e-03\n",
      " -4.8372191e-03 -7.5749049e-05 -3.7358410e-03 -2.9316905e-03\n",
      " -1.4724307e-03  1.7335851e-03  2.3317900e-03  1.4056792e-03\n",
      " -4.2503504e-03 -3.4267770e-03  1.1639629e-03 -7.1433419e-04\n",
      " -4.1077770e-03  2.2701940e-03 -3.3797924e-03 -3.2200566e-03\n",
      " -6.5178279e-04  1.7330556e-03  1.0621746e-03  1.8330537e-03\n",
      " -4.9825143e-03  3.4724378e-03 -3.9547710e-03 -4.6596820e-03\n",
      " -4.6293112e-03  2.0458298e-03  1.0679327e-03 -4.6836116e-04\n",
      " -3.2816688e-03 -3.8043805e-03  1.0991084e-03 -3.4835679e-03\n",
      " -4.6645771e-03  3.3895015e-03 -1.6473000e-03  2.8420193e-03\n",
      " -4.1401383e-04 -6.9892913e-04 -4.9152924e-03 -2.3460728e-03\n",
      " -3.9904737e-03  4.7757658e-03  4.7878260e-03 -4.8298123e-03\n",
      " -1.3256365e-03  3.2011732e-03  4.2378167e-03 -2.2786660e-03\n",
      "  1.8032138e-03 -3.6375970e-03  4.9273740e-03 -5.9725234e-04\n",
      "  4.0769707e-03  3.5920651e-03  1.5874747e-03 -1.9807003e-03\n",
      " -2.4871957e-03 -9.2655263e-04 -1.2553267e-03  4.7638817e-03\n",
      " -2.6315141e-03  4.7106557e-03 -1.2998409e-03 -3.7264464e-05\n",
      "  4.7493512e-03  7.5058470e-04 -3.6369280e-03  3.1131327e-03\n",
      " -1.8785421e-03 -3.8929116e-03 -1.9588950e-03  3.3274633e-03\n",
      "  1.5628440e-03  1.6172001e-03 -4.4787126e-03  1.3439899e-03\n",
      "  2.2695081e-03 -3.3182558e-03  2.7581365e-03 -1.5928937e-03\n",
      "  4.0326617e-03 -3.7088396e-03  9.8571461e-04  3.9527258e-03\n",
      " -2.3207038e-04 -1.6781418e-03 -2.2980860e-03  4.9648071e-03]\n"
     ]
    }
   ],
   "source": [
    "#Summarize the loaded model\n",
    "print(model_cbow)\n",
    "\n",
    "#Summarize vocabulary\n",
    "words = list(model_cbow.wv.vocab)\n",
    "print(words)\n",
    "\n",
    "#Acess vector for one word\n",
    "print(model_cbow['dog'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-05T21:26:57.420196Z",
     "start_time": "2021-04-05T21:26:57.417193Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "id": "gMuHv52GeuoR",
    "outputId": "b498032d-6f9d-485b-a3cc-5a21300bfb06"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity between eats and bites: -0.005390561\n",
      "Similarity between eats and man: 0.015573241\n"
     ]
    }
   ],
   "source": [
    "#Compute similarity \n",
    "print(\"Similarity between eats and bites:\",model_cbow.similarity('eats', 'bites'))\n",
    "print(\"Similarity between eats and man:\",model_cbow.similarity('eats', 'man'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "twhTZfPOezTU"
   },
   "source": [
    "From the above similarity scores we can conclude that eats is more similar to bites than man."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-05T21:26:59.635831Z",
     "start_time": "2021-04-05T21:26:59.621818Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 104
    },
    "colab_type": "code",
    "id": "5Lv0V7WofmsB",
    "outputId": "00600b23-d9a6-4f14-bacd-395be85076c8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('bites', 0.15752582252025604),\n",
       " ('eats', -0.004543561488389969),\n",
       " ('food', -0.0699436366558075),\n",
       " ('dog', -0.14076852798461914),\n",
       " ('man', -0.14991554617881775)]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Most similarity\n",
    "model_cbow.most_similar('meat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-05T21:26:59.855822Z",
     "start_time": "2021-04-05T21:26:59.841810Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "WA783nrSalgs",
    "outputId": "80d6e23f-2bed-47d7-f925-4aaa87ec5f9e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word2Vec(vocab=6, size=100, alpha=0.025)\n"
     ]
    }
   ],
   "source": [
    "# save model\n",
    "model_cbow.save('model_cbow.bin')\n",
    "\n",
    "# load model\n",
    "new_model_cbow = Word2Vec.load('model_cbow.bin')\n",
    "print(new_model_cbow)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "deReLSI7mQyr"
   },
   "source": [
    "## SkipGram\n",
    "In skipgram, the task is to predict the context words from the center word."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-05T21:27:00.517046Z",
     "start_time": "2021-04-05T21:27:00.508038Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 486
    },
    "colab_type": "code",
    "id": "9QtUtsLglvY0",
    "outputId": "6d19902b-66aa-4b0f-9f12-be18f37d40d1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word2Vec(vocab=6, size=100, alpha=0.025)\n",
      "['dog', 'bites', 'man', 'eats', 'meat', 'food']\n",
      "[-3.9270632e-03  2.9621110e-03 -3.7891304e-03  2.8326416e-03\n",
      "  2.3133212e-03  3.7316212e-03 -3.8585411e-03  2.6184537e-03\n",
      "  3.0876028e-03  2.1837868e-03 -2.7802046e-03  3.0769829e-03\n",
      " -4.8372191e-03 -7.5749049e-05 -3.7358410e-03 -2.9316905e-03\n",
      " -1.4724307e-03  1.7335851e-03  2.3317900e-03  1.4056792e-03\n",
      " -4.2503504e-03 -3.4267770e-03  1.1639629e-03 -7.1433419e-04\n",
      " -4.1077770e-03  2.2701940e-03 -3.3797924e-03 -3.2200566e-03\n",
      " -6.5178279e-04  1.7330556e-03  1.0621746e-03  1.8330537e-03\n",
      " -4.9825143e-03  3.4724378e-03 -3.9547710e-03 -4.6596820e-03\n",
      " -4.6293112e-03  2.0458298e-03  1.0679327e-03 -4.6836116e-04\n",
      " -3.2816688e-03 -3.8043805e-03  1.0991084e-03 -3.4835679e-03\n",
      " -4.6645771e-03  3.3895015e-03 -1.6473000e-03  2.8420193e-03\n",
      " -4.1401383e-04 -6.9892913e-04 -4.9152924e-03 -2.3460728e-03\n",
      " -3.9904737e-03  4.7757658e-03  4.7878260e-03 -4.8298123e-03\n",
      " -1.3256365e-03  3.2011732e-03  4.2378167e-03 -2.2786660e-03\n",
      "  1.8032138e-03 -3.6375970e-03  4.9273740e-03 -5.9725234e-04\n",
      "  4.0769707e-03  3.5920651e-03  1.5874747e-03 -1.9807003e-03\n",
      " -2.4871957e-03 -9.2655263e-04 -1.2553267e-03  4.7638817e-03\n",
      " -2.6315141e-03  4.7106557e-03 -1.2998409e-03 -3.7264464e-05\n",
      "  4.7493512e-03  7.5058470e-04 -3.6369280e-03  3.1131327e-03\n",
      " -1.8785421e-03 -3.8929116e-03 -1.9588950e-03  3.3274633e-03\n",
      "  1.5628440e-03  1.6172001e-03 -4.4787126e-03  1.3439899e-03\n",
      "  2.2695081e-03 -3.3182558e-03  2.7581365e-03 -1.5928937e-03\n",
      "  4.0326617e-03 -3.7088396e-03  9.8571461e-04  3.9527258e-03\n",
      " -2.3207038e-04 -1.6781418e-03 -2.2980860e-03  4.9648071e-03]\n"
     ]
    }
   ],
   "source": [
    "#Summarize the loaded model\n",
    "print(model_skipgram)\n",
    "\n",
    "#Summarize vocabulary\n",
    "words = list(model_skipgram.wv.vocab)\n",
    "print(words)\n",
    "\n",
    "#Acess vector for one word\n",
    "print(model_skipgram['dog'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-05T21:27:02.660747Z",
     "start_time": "2021-04-05T21:27:02.642866Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "id": "8YUsblEOfFWf",
    "outputId": "14cd759c-d5fc-465f-ed20-8fd1a1949168"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity between eats and bites: -0.0054028155\n",
      "Similarity between eats and man: 0.01558489\n"
     ]
    }
   ],
   "source": [
    "#Compute similarity \n",
    "print(\"Similarity between eats and bites:\",model_skipgram.similarity('eats', 'bites'))\n",
    "print(\"Similarity between eats and man:\",model_skipgram.similarity('eats', 'man'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gdXVDePKnBpv"
   },
   "source": [
    "From the above similarity scores we can conclude that eats is more similar to bites than man."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-05T21:27:03.419546Z",
     "start_time": "2021-04-05T21:27:03.414541Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 104
    },
    "colab_type": "code",
    "id": "lpF4qtwpmuM3",
    "outputId": "f3bc68f6-3768-4a4d-e5bc-bb3dff6f654f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('bites', 0.15752583742141724),\n",
       " ('eats', -0.00462137907743454),\n",
       " ('food', -0.06994364410638809),\n",
       " ('dog', -0.14076852798461914),\n",
       " ('man', -0.14991557598114014)]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Most similarity\n",
    "model_skipgram.most_similar('meat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-05T21:27:03.973454Z",
     "start_time": "2021-04-05T21:27:03.950433Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "aNDCEXRTnAnj",
    "outputId": "402f77b6-0625-4b37-e135-3650df626007"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word2Vec(vocab=6, size=100, alpha=0.025)\n"
     ]
    }
   ],
   "source": [
    "# save model\n",
    "model_skipgram.save('model_skipgram.bin')\n",
    "\n",
    "# load model\n",
    "new_model_skipgram = Word2Vec.load('model_skipgram.bin')\n",
    "print(model_skipgram)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "b0MiqJ_1M0mX"
   },
   "source": [
    "## Training Your Embedding on Wiki Corpus\n",
    "\n",
    "##### The corpus download page : https://dumps.wikimedia.org/enwiki/20200120/\n",
    "The entire wiki corpus as of 28/04/2020 is just over 16GB in size.\n",
    "We will take a part of this corpus due to computation constraints and train our word2vec and fasttext embeddings.\n",
    "\n",
    "The file size is 294MB so it can take a while to download.\n",
    "\n",
    "Source for code which downloads files from Google Drive: https://stackoverflow.com/questions/25010369/wget-curl-large-file-from-google-drive/39225039#39225039"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-05T21:27:58.596845Z",
     "start_time": "2021-04-05T21:27:58.585833Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File at: data/en/enwiki-latest-pages-articles-multistream14.xml-p13159683p14324602.bz2\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import requests\n",
    "\n",
    "os.makedirs('data/en', exist_ok= True)\n",
    "file_name = \"data/en/enwiki-latest-pages-articles-multistream14.xml-p13159683p14324602.bz2\"\n",
    "file_id = \"11804g0GcWnBIVDahjo5fQyc05nQLXGwF\"\n",
    "\n",
    "def download_file_from_google_drive(id, destination):\n",
    "    URL = \"https://docs.google.com/uc?export=download\"\n",
    "\n",
    "    session = requests.Session()\n",
    "\n",
    "    response = session.get(URL, params = { 'id' : id }, stream = True)\n",
    "    token = get_confirm_token(response)\n",
    "\n",
    "    if token:\n",
    "        params = { 'id' : id, 'confirm' : token }\n",
    "        response = session.get(URL, params = params, stream = True)\n",
    "\n",
    "    save_response_content(response, destination)    \n",
    "\n",
    "def get_confirm_token(response):\n",
    "    for key, value in response.cookies.items():\n",
    "        if key.startswith('download_warning'):\n",
    "            return value\n",
    "\n",
    "    return None\n",
    "\n",
    "def save_response_content(response, destination):\n",
    "    CHUNK_SIZE = 32768\n",
    "\n",
    "    with open(destination, \"wb\") as f:\n",
    "        for chunk in response.iter_content(CHUNK_SIZE):\n",
    "            if chunk: # filter out keep-alive new chunks\n",
    "                f.write(chunk)\n",
    "\n",
    "if not os.path.exists(file_name):\n",
    "    download_file_from_google_drive(file_id, file_name)\n",
    "else:\n",
    "    print(\"file already exists, skipping download\")\n",
    "\n",
    "print(f\"File at: {file_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-03T08:59:17.024306Z",
     "start_time": "2021-04-03T08:59:17.022304Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "wX1kx96JLYvt"
   },
   "outputs": [],
   "source": [
    "from gensim.corpora.wikicorpus import WikiCorpus\n",
    "from gensim.models.word2vec import Word2Vec\n",
    "from gensim.models.fasttext import FastText\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-03T09:56:14.722195Z",
     "start_time": "2021-04-03T09:56:14.705177Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "rJgsEUmRPppc"
   },
   "outputs": [],
   "source": [
    "#Preparing the Training data\n",
    "wiki = WikiCorpus(file_name, lemmatize=False, dictionary={})\n",
    "sentences = list(wiki.get_texts())\n",
    "\n",
    "#if you get a memory error executing the lines above\n",
    "#comment the lines out and uncomment the lines below. \n",
    "#loading will be slower, but stable.\n",
    "# wiki = WikiCorpus(file_name, processes=4, lemmatize=False, dictionary={})\n",
    "# sentences = list(wiki.get_texts())\n",
    "\n",
    "#if you still get a memory error, try settings processes to 1 or 2 and then run it again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['saint', 'tricat', 'is', 'commune', 'in', 'the', 'pas', 'de', 'calais', 'department', 'in', 'the', 'hauts', 'de', 'france', 'region', 'of', 'france', 'geography', 'saint', 'tricat', 'is', 'located', 'miles', 'km', 'southwest', 'of', 'calais', 'at', 'the', 'junction', 'of', 'the', 'and', 'roads', 'population', 'places', 'of', 'interest', 'the', 'church', 'of', 'st', 'nicaise', 'dating', 'from', 'the', 'twelfth', 'century', 'see', 'also', 'communes', 'of', 'the', 'pas', 'de', 'calais', 'department', 'references', 'insee', 'commune', 'file']\n"
     ]
    }
   ],
   "source": [
    "print (sentences[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xsIrgt_gPQda"
   },
   "source": [
    "### Hyperparameters\n",
    "\n",
    "\n",
    "1.   sg - Selecting the training algorithm: 1 for skip-gram else its 0 for CBOW. Default is CBOW.\n",
    "2.   min_count-  Ignores all words with total frequency lower than this.<br>\n",
    "There are many more hyperparamaeters whose list can be found in the official documentation [here.](https://radimrehurek.com/gensim/models/word2vec.html)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-03T10:01:20.065332Z",
     "start_time": "2021-04-03T09:59:12.350872Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "id": "idmfbr_8LvoN",
    "outputId": "f505a46e-025d-4169-f996-06c672008f81"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CBOW Model Training Complete.\n",
      "Time taken for training is:0.05 hrs \n"
     ]
    }
   ],
   "source": [
    "#CBOW\n",
    "start = time.time()\n",
    "word2vec_cbow = Word2Vec(sentences,min_count=10, sg=0)\n",
    "end = time.time()\n",
    "\n",
    "print(\"CBOW Model Training Complete.\\nTime taken for training is:{:.2f} hrs \".format((end-start)/3600.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-03T10:02:10.613551Z",
     "start_time": "2021-04-03T10:02:10.585535Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 471
    },
    "colab_type": "code",
    "id": "mMdGn08-RkhM",
    "outputId": "efb34148-3fb4-435c-f070-8493708fc07a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word2Vec(vocab=111150, size=100, alpha=0.025)\n",
      "------------------------------\n",
      "Length of vocabulary: 111150\n",
      "Printing the first 30 words.\n",
      "['the', 'roses', 'registered', 'as', 'is', 'brisbane', 'racing', 'club', 'group', 'thoroughbred', 'horse', 'race', 'for', 'three', 'year', 'old', 'filles', 'run', 'under', 'set', 'weights', 'conditions', 'over', 'distance', 'of', 'metres', 'at', 'racecourse', 'australia', 'during']\n",
      "------------------------------\n",
      "Length of vector: 100\n",
      "[-0.25941572 -1.6287326   2.5331333  -1.5818936   0.9024474   0.8614945\n",
      "  2.4875445  -0.95802265 -1.3792082  -1.1744157  -4.300686    1.0071316\n",
      "  0.10418405  4.855032    0.6251962  -0.06472338  0.19993098 -0.7291219\n",
      "  2.342258   -1.7298651   0.7895099  -2.2819378   0.7158192  -0.62419826\n",
      "  0.6720258   3.6712303   1.3836899   0.17808275 -3.7205396   0.2529162\n",
      "  1.0290879  -0.9228959   0.9451632   1.7415334   1.9618814   1.4535053\n",
      "  2.670452    0.9272077   0.25056183 -0.4078236   0.5795217   0.6316829\n",
      "  0.50204426 -0.19865237 -2.697352    0.75351495  1.0796617   2.247825\n",
      " -2.956658    2.6606686  -0.42392135 -0.44319883 -2.9274392  -1.0198026\n",
      "  1.404833   -0.10840467  0.50829273  1.0767945  -0.65002084 -3.4231277\n",
      "  4.719826   -1.5996053   0.82882935  1.635043   -0.45730942 -1.3166244\n",
      " -1.3349417  -2.3565981   1.7141095  -2.6643796  -1.2148786   0.2972199\n",
      " -2.2865987  -1.6022073   2.0965865  -0.87479544 -1.4143106  -0.9149557\n",
      "  2.2900226   1.1464663  -2.6113467  -1.5517493   1.3018385   4.1072307\n",
      "  1.1441547   1.0222696   0.4847384   2.4148073  -2.881392   -0.67044157\n",
      " -2.482836   -0.417894    3.1442287  -1.6087203   1.865813   -3.717568\n",
      "  0.5994761   1.8819104   3.355772   -1.9087372 ]\n",
      "------------------------------\n",
      "Similarity between film and drama: 0.4986632\n",
      "Similarity between film and tiger: 0.15477756\n",
      "------------------------------\n"
     ]
    }
   ],
   "source": [
    "#Summarize the loaded model\n",
    "print(word2vec_cbow)\n",
    "print(\"-\"*30)\n",
    "\n",
    "#Summarize vocabulary\n",
    "words = list(word2vec_cbow.wv.vocab)\n",
    "print(f\"Length of vocabulary: {len(words)}\")\n",
    "print(\"Printing the first 30 words.\")\n",
    "print(words[:30])\n",
    "print(\"-\"*30)\n",
    "\n",
    "#Acess vector for one word\n",
    "print(f\"Length of vector: {len(word2vec_cbow['film'])}\")\n",
    "print(word2vec_cbow['film'])\n",
    "print(\"-\"*30)\n",
    "\n",
    "#Compute similarity \n",
    "print(\"Similarity between film and drama:\",word2vec_cbow.similarity('film', 'drama'))\n",
    "print(\"Similarity between film and tiger:\",word2vec_cbow.similarity('film', 'tiger'))\n",
    "print(\"-\"*30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-03T10:02:16.109851Z",
     "start_time": "2021-04-03T10:02:15.257052Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "rXrDOrKskcHX"
   },
   "outputs": [],
   "source": [
    "# save model\n",
    "from gensim.models import Word2Vec, KeyedVectors   \n",
    "word2vec_cbow.wv.save_word2vec_format('word2vec_cbow.bin', binary=True)\n",
    "\n",
    "# load model\n",
    "# new_modelword2vec_cbow = Word2Vec.load('word2vec_cbow.bin')\n",
    "# print(word2vec_cbow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-03T10:08:27.736688Z",
     "start_time": "2021-04-03T10:02:19.197708Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "id": "dX0U0CbQOK30",
    "outputId": "b9bfcf2b-91cb-40d9-ca92-791ec346aef4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SkipGram Model Training Complete\n",
      "Time taken for training is:0.10 hrs \n"
     ]
    }
   ],
   "source": [
    "#SkipGram\n",
    "start = time.time()\n",
    "word2vec_skipgram = Word2Vec(sentences,min_count=10, sg=1)\n",
    "end = time.time()\n",
    "\n",
    "print(\"SkipGram Model Training Complete\\nTime taken for training is:{:.2f} hrs \".format((end-start)/3600.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-03T10:09:06.406929Z",
     "start_time": "2021-04-03T10:09:06.383908Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 471
    },
    "colab_type": "code",
    "id": "LXnY9YInSvnI",
    "outputId": "26f1dab7-27a6-4655-81c7-ac6f08fe1f9c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word2Vec(vocab=111150, size=100, alpha=0.025)\n",
      "------------------------------\n",
      "Length of vocabulary: 111150\n",
      "Printing the first 30 words.\n",
      "['the', 'roses', 'registered', 'as', 'is', 'brisbane', 'racing', 'club', 'group', 'thoroughbred', 'horse', 'race', 'for', 'three', 'year', 'old', 'filles', 'run', 'under', 'set', 'weights', 'conditions', 'over', 'distance', 'of', 'metres', 'at', 'racecourse', 'australia', 'during']\n",
      "------------------------------\n",
      "Length of vector: 100\n",
      "[ 1.94889292e-01 -7.88324535e-01  4.66947220e-02  2.57520348e-01\n",
      "  2.65304267e-01  3.63538593e-01  4.63590741e-01 -1.62654325e-01\n",
      "  9.11010578e-02 -6.58479631e-02 -6.97350129e-02 -6.56900406e-02\n",
      "  2.19506964e-01  2.20394313e-01  1.05092540e-01  8.26439075e-03\n",
      " -9.39796269e-02  5.50851583e-01  7.65753444e-04 -2.22807571e-01\n",
      " -3.17346871e-01  3.20529372e-01  4.51157093e-02 -1.93709806e-01\n",
      "  2.07626969e-02  1.69344515e-01  2.77250055e-02  1.10369585e-02\n",
      " -4.75540310e-01  1.10796697e-01  4.28172469e-01  4.06191871e-02\n",
      "  5.15495241e-01 -6.85295224e-01 -5.06723702e-01 -4.52192919e-03\n",
      "  1.51265517e-03 -3.84557724e-01 -2.22782314e-01  5.11201501e-01\n",
      "  1.42252162e-01 -7.73397386e-01 -2.78606623e-01  4.70017433e-01\n",
      " -2.70037323e-01  5.04850507e-01 -1.48356587e-01  2.26073325e-01\n",
      " -3.36060971e-01 -1.19667962e-01 -2.59654850e-01 -4.44965392e-01\n",
      "  1.11614995e-01  1.62986945e-02  4.82374012e-01 -7.87460804e-02\n",
      " -1.13825299e-01 -2.24003598e-01  4.93353546e-01 -5.57069406e-02\n",
      "  2.43176505e-01 -1.84876159e-01  2.13489812e-02  3.42909366e-01\n",
      "  2.02496469e-01 -4.25657362e-01  8.17572057e-01 -2.83644646e-01\n",
      " -5.23434244e-02 -3.27616245e-01  4.43994589e-02 -3.90237272e-01\n",
      "  2.12029487e-01 -7.25788534e-01  5.52469850e-01 -4.72590374e-03\n",
      " -2.02829018e-01 -9.59078223e-03  3.68973225e-01 -2.69762665e-01\n",
      " -2.85591751e-01 -2.68359333e-01  3.10093671e-01  2.02198789e-01\n",
      "  5.80960453e-01 -2.47493789e-01 -7.37856887e-03 -3.59723950e-03\n",
      "  3.14893663e-01  1.12885557e-01 -5.09416103e-01 -7.58459032e-01\n",
      "  5.30587435e-01 -1.51896626e-01 -3.37440372e-01  4.22841489e-01\n",
      " -3.34523350e-01  3.21759552e-01  7.44457126e-01 -1.26014173e-01]\n",
      "------------------------------\n",
      "Similarity between film and drama: 0.63833964\n",
      "Similarity between film and tiger: 0.22270091\n",
      "------------------------------\n"
     ]
    }
   ],
   "source": [
    "#Summarize the loaded model\n",
    "print(word2vec_skipgram)\n",
    "print(\"-\"*30)\n",
    "\n",
    "#Summarize vocabulary\n",
    "words = list(word2vec_skipgram.wv.vocab)\n",
    "print(f\"Length of vocabulary: {len(words)}\")\n",
    "print(\"Printing the first 30 words.\")\n",
    "print(words[:30])\n",
    "print(\"-\"*30)\n",
    "\n",
    "#Acess vector for one word\n",
    "print(f\"Length of vector: {len(word2vec_skipgram['film'])}\")\n",
    "print(word2vec_skipgram['film'])\n",
    "print(\"-\"*30)\n",
    "\n",
    "#Compute similarity \n",
    "print(\"Similarity between film and drama:\",word2vec_skipgram.similarity('film', 'drama'))\n",
    "print(\"Similarity between film and tiger:\",word2vec_skipgram.similarity('film', 'tiger'))\n",
    "print(\"-\"*30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-03T10:09:09.947695Z",
     "start_time": "2021-04-03T10:09:09.076901Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "o8U7bfPSVB04"
   },
   "outputs": [],
   "source": [
    "# save model\n",
    "word2vec_cbow.wv.save_word2vec_format('word2vec_sg.bin', binary=True)\n",
    "\n",
    "# load model\n",
    "# new_model_skipgram = Word2Vec.load('model_skipgram.bin')\n",
    "# print(model_skipgram)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kExlA8kfrKml"
   },
   "source": [
    "## FastText"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-03T10:16:31.271764Z",
     "start_time": "2021-04-03T10:09:16.592670Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "id": "JPd2VhMEk8gL",
    "outputId": "55c44bdd-d7d8-4df2-8140-cdd442bbd68c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FastText CBOW Model Training Complete\n",
      "Time taken for training is:0.12 hrs \n"
     ]
    }
   ],
   "source": [
    "#CBOW\n",
    "start = time.time()\n",
    "fasttext_cbow = FastText(sentences, sg=0, min_count=10)\n",
    "end = time.time()\n",
    "\n",
    "print(\"FastText CBOW Model Training Complete\\nTime taken for training is:{:.2f} hrs \".format((end-start)/3600.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-03T10:16:31.287283Z",
     "start_time": "2021-04-03T10:16:31.273765Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 471
    },
    "colab_type": "code",
    "id": "FlQFl8-Zsost",
    "outputId": "6472e944-e6de-4d64-8c6f-14475ef1eac5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FastText(vocab=111150, size=100, alpha=0.025)\n",
      "------------------------------\n",
      "Length of vocabulary: 111150\n",
      "Printing the first 30 words.\n",
      "['the', 'roses', 'registered', 'as', 'is', 'brisbane', 'racing', 'club', 'group', 'thoroughbred', 'horse', 'race', 'for', 'three', 'year', 'old', 'filles', 'run', 'under', 'set', 'weights', 'conditions', 'over', 'distance', 'of', 'metres', 'at', 'racecourse', 'australia', 'during']\n",
      "------------------------------\n",
      "Length of vector: 100\n",
      "[ 0.47473213  1.6783198  -4.766255   -3.2404876   0.80164665  1.993539\n",
      "  3.4226568  -0.7035685  -3.0426116   1.5137119   3.8207133   1.3821473\n",
      " -0.7379625  -0.6726444   1.8303355  -2.1288188   1.2368282  -3.0745962\n",
      "  1.4226121  -2.8884995   7.2847705  -1.564321    2.869352    0.6962616\n",
      "  4.469778    2.5569658   2.621335   -4.612509   -2.2389078   3.6648748\n",
      "  0.7189718   1.0702186  -3.175641    2.7648733   0.13811935 -2.441776\n",
      " -3.9559126  -0.03163956 -1.1257534  -0.64402825 -1.5076644  -0.58919376\n",
      " -0.14338583  4.2466817   4.3784213   3.0076942  -5.972965    2.2950342\n",
      " -0.50719374 -3.916504   -2.1366098  -2.661619    2.3540869   2.1862476\n",
      "  5.1004434   4.1282     -4.164653    1.1288711  -4.001655   -4.051289\n",
      "  2.5718336  -0.40600455  3.8396242   2.214367    1.8413899   4.5216975\n",
      " -1.6419586   2.7617378  -2.0902452   2.598776    4.041824   -5.1805005\n",
      " -2.777213   -0.02546828 -0.07393612 -3.2800605  -2.9874747  -0.6490991\n",
      "  3.6039045  -1.4168853   3.6110177  -1.0872458  -0.6365031  -1.0161037\n",
      "  3.7344344   0.29839793  0.421953   -1.811646    1.3730506   7.575645\n",
      "  3.3998368   5.0335827  -0.2107324  -2.331183    0.19383769  3.0550041\n",
      "  4.1529713   3.988616    0.04955976  1.3424706 ]\n",
      "------------------------------\n",
      "Similarity between film and drama: 0.5669882\n",
      "Similarity between film and tiger: 0.24975622\n",
      "------------------------------\n"
     ]
    }
   ],
   "source": [
    "#Summarize the loaded model\n",
    "print(fasttext_cbow)\n",
    "print(\"-\"*30)\n",
    "\n",
    "#Summarize vocabulary\n",
    "words = list(fasttext_cbow.wv.vocab)\n",
    "print(f\"Length of vocabulary: {len(words)}\")\n",
    "print(\"Printing the first 30 words.\")\n",
    "print(words[:30])\n",
    "print(\"-\"*30)\n",
    "\n",
    "#Acess vector for one word\n",
    "print(f\"Length of vector: {len(fasttext_cbow['film'])}\")\n",
    "print(fasttext_cbow['film'])\n",
    "print(\"-\"*30)\n",
    "\n",
    "#Compute similarity \n",
    "print(\"Similarity between film and drama:\",fasttext_cbow.similarity('film', 'drama'))\n",
    "print(\"Similarity between film and tiger:\",fasttext_cbow.similarity('film', 'tiger'))\n",
    "print(\"-\"*30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-03T10:28:28.771383Z",
     "start_time": "2021-04-03T10:16:31.289284Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "id": "UgSOxsNklAvh",
    "outputId": "f491f83c-17b8-42ad-a225-479df8419578"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FastText SkipGram Model Training Complete\n",
      "Time taken for training is:0.20 hrs \n"
     ]
    }
   ],
   "source": [
    "#SkipGram\n",
    "start = time.time()\n",
    "fasttext_skipgram = FastText(sentences, sg=1, min_count=10)\n",
    "end = time.time()\n",
    "\n",
    "print(\"FastText SkipGram Model Training Complete\\nTime taken for training is:{:.2f} hrs \".format((end-start)/3600.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-03T10:28:28.803412Z",
     "start_time": "2021-04-03T10:28:28.773386Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 610
    },
    "colab_type": "code",
    "id": "vFiTAP0PsQwi",
    "outputId": "a29ae2e3-5dbc-453a-f66b-ceca255a8652"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FastText(vocab=111150, size=100, alpha=0.025)\n",
      "------------------------------\n",
      "Length of vocabulary: 111150\n",
      "Printing the first 30 words.\n",
      "['the', 'roses', 'registered', 'as', 'is', 'brisbane', 'racing', 'club', 'group', 'thoroughbred', 'horse', 'race', 'for', 'three', 'year', 'old', 'filles', 'run', 'under', 'set', 'weights', 'conditions', 'over', 'distance', 'of', 'metres', 'at', 'racecourse', 'australia', 'during']\n",
      "------------------------------\n",
      "Length of vector: 100\n",
      "[-8.4101312e-02 -6.9478154e-04  3.3954462e-01 -3.6973858e-01\n",
      "  1.6844368e-01  3.4855682e-01  8.0026442e-01 -5.0405812e-01\n",
      " -6.0389137e-01  2.1694953e-02  4.0937051e-01 -3.5893116e-02\n",
      " -1.3717794e-01  4.0389201e-01  3.9567137e-01  2.4365921e-01\n",
      "  5.6551516e-02 -1.5994829e-01 -1.8148309e-01 -2.6480275e-01\n",
      " -4.8462763e-01  9.5473409e-02 -1.1126036e-02 -1.8805853e-01\n",
      "  2.4277805e-01  2.4251699e-01 -1.7501226e-01 -4.3078136e-01\n",
      " -3.6442232e-01  9.1702184e-03 -3.2344624e-01 -1.0232232e-01\n",
      " -5.2684498e-01 -2.7622378e-01  4.2112619e-01 -4.3196991e-02\n",
      "  3.1967857e-01  1.7001998e-01  3.3157614e-01 -2.4995559e-01\n",
      " -1.3239473e-01 -3.4502399e-01  2.1341468e-01  5.8890671e-01\n",
      "  1.7721146e-01  1.5974782e-01 -3.8579264e-01 -2.8241745e-01\n",
      "  6.7402735e-02 -7.1903253e-01  1.3665260e-01 -5.9633050e-02\n",
      " -5.9002697e-01 -6.1173952e-01 -1.0246418e-03 -5.1254374e-01\n",
      " -1.5101396e-01  1.6967247e-01  2.8125226e-01 -4.6728057e-01\n",
      " -5.4966863e-02 -1.3736627e-02 -1.5689149e-01  8.3176725e-02\n",
      "  1.8850440e-02  4.1858605e-01 -1.1376646e-02 -4.0758383e-02\n",
      " -1.7871203e-01  2.7792713e-01  5.5813068e-01 -3.5465869e-01\n",
      "  1.3662770e-01  2.5777066e-01 -3.0423281e-01  7.8141141e-01\n",
      "  1.1446947e-02 -4.0541172e-01  2.9406905e-01  6.0151044e-02\n",
      "  4.9637925e-02 -3.9679220e-01  4.5333567e-01  1.0888510e-02\n",
      "  2.7147910e-01 -1.7305572e-01 -2.8098795e-01 -6.1907400e-03\n",
      " -2.3080334e-01  5.8609635e-01 -1.0097053e-01  6.6119152e-01\n",
      "  1.8578811e-01 -5.9025098e-02 -5.3886050e-01  2.6664239e-01\n",
      " -2.2193529e-02  7.0487672e-01  3.9477929e-01  3.7981489e-01]\n",
      "------------------------------\n",
      "Similarity between film and drama: 0.626041\n",
      "Similarity between film and tiger: 0.27831402\n",
      "------------------------------\n"
     ]
    }
   ],
   "source": [
    "#Summarize the loaded model\n",
    "print(fasttext_skipgram)\n",
    "print(\"-\"*30)\n",
    "\n",
    "#Summarize vocabulary\n",
    "words = list(fasttext_skipgram.wv.vocab)\n",
    "print(f\"Length of vocabulary: {len(words)}\")\n",
    "print(\"Printing the first 30 words.\")\n",
    "print(words[:30])\n",
    "print(\"-\"*30)\n",
    "\n",
    "#Acess vector for one word\n",
    "print(f\"Length of vector: {len(fasttext_skipgram['film'])}\")\n",
    "print(fasttext_skipgram['film'])\n",
    "print(\"-\"*30)\n",
    "\n",
    "#Compute similarity \n",
    "print(\"Similarity between film and drama:\",fasttext_skipgram.similarity('film', 'drama'))\n",
    "print(\"Similarity between film and tiger:\",fasttext_skipgram.similarity('film', 'tiger'))\n",
    "print(\"-\"*30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "oArMIJzYOmUR"
   },
   "source": [
    "#### An interesting obeseravtion if you noticed is that CBOW trains faster than SkipGram in both cases.\n",
    "We will leave it to the user to figure out why. A hint would be to refer the working of CBOW and skipgram."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "machine_shape": "hm",
   "name": "Training_embeddings_using_gensim.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
